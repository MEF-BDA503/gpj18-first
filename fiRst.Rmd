---
title: "InitialAnalysis"
author: "Efehan Danýþman"
date: "11 Kasým 2018"
output: html_document
---

```{r setup, include=FALSE,eval=TRUE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(forcats)
library(scales)
library(knitr)
library(lubridate)
library(RColorBrewer)
```

## R Markdown

We obtained electricty cuts data in Turkey between 2012 and 2018 from the Energy Transparency Platform. Data contain 51630 rows and 7 variables.

Objectives of this project is as follows:

# Learning Objectives
* Cleaning dirty data and doing text mining in order to extract insights.
* Visualizing data according to different variables.
* Visualizing geographical data over the map.

# Analysis Objectives
* Finding longest and shortest cuts and visualizing them.
* Visualizing cuts at the power plants according to city and duration.
* Finding top reasons of electricity cuts with tidy text mining.
* Analyzing cuts vis-a-vis to capacity and total power at the power plant.

```{r Getting the Data}
# Create a temporary file
tmp<-tempfile(fileext=".csv")
# Download file from repository to the temp file
download.file("https://github.com/MEF-BDA503/gpj18-first/blob/master/dataset_candidates/ArizaBakim-01012008-25112018.csv?raw=True",destfile=tmp)
```

```{r Initial Cleaning and Analysis}
# Reading data. Encoding as Latin-1 is crucial in order to see Turkish characters properly.
cuts<-read.csv(tmp, encoding= "Latin-1", header=TRUE,row.names=NULL,sep=";")
# Checking what we have as data.
str(cuts)
# Convert type of time and date to date
cuts$Olay.Baþlangýç.Tarihi <- dmy_hm(cuts$Olay.Baþlangýç.Tarihi)
cuts$Olay.Bitiþ.Tarihi <- dmy_hm(cuts$Olay.Bitiþ.Tarihi)

# Turn power capacity variables into numeric. First clean the dots so they will not be considered as decimals while separating thousands. Then turn commas into dots so that we can have proper decimals.

cuts$Ýþletmedeki.Kurulu.Güç <- gsub("\\.","",cuts$Ýþletmedeki.Kurulu.Güç) 
cuts$Olay.Sýrasýnda.Kapasite<- gsub("\\.","",cuts$Olay.Sýrasýnda.Kapasite) 
cuts$Ýþletmedeki.Kurulu.Güç <- gsub(",",".",cuts$Ýþletmedeki.Kurulu.Güç) 
cuts$Olay.Sýrasýnda.Kapasite<- gsub(",",".",cuts$Olay.Sýrasýnda.Kapasite) 
cuts$Ýþletmedeki.Kurulu.Güç <- as.numeric(as.character(cuts$Ýþletmedeki.Kurulu.Güç))
cuts$Olay.Sýrasýnda.Kapasite <- as.numeric(as.character(cuts$Olay.Sýrasýnda.Kapasite))

#Verify that we finally have numeric values.
str(cuts$Ýþletmedeki.Kurulu.Güç)
str(cuts$Olay.Sýrasýnda.Kapasite)

# Looks like data is until beginning of the 2018 and we have between 10-12K cuts per year between 2014 and 2017.
yearly_cuts <- cuts %>% group_by(year=floor_date(Olay.Baþlangýç.Tarihi,"year")) %>% summarize(Olay.Baþlangýç.Tarihi=n())
yearly_cuts
```

```{r Plot}
# Let's put the yearly cuts into a bar graph.
ggplot(data=yearly_cuts, aes(y=Olay.Baþlangýç.Tarihi, x=factor(year(year)), fill=factor(year(year))))+
  geom_bar(stat="identity")+
  labs(x="Year", y="Incident Count", title="Yearly Total Incidents")+
  theme_light()+
  scale_fill_brewer(palette="PuBuGn")+
  theme(legend.position="none")
```

```{r New Variables For Calculations}
#Adding süre variable as duration of the cuts as hours and capacity usage ratio at time of cut as capacity usage's ratio to total capacity.
cuts <- cuts %>% mutate(sure = difftime(Olay.Bitiþ.Tarihi,Olay.Baþlangýç.Tarihi,units="hours")) %>% mutate(kapasiteorani = Olay.Sýrasýnda.Kapasite / Ýþletmedeki.Kurulu.Güç)
# Make all strings lower case so that can be cleaned easier.
cuts <- mutate_all(cuts, funs(tolower))

```

```{r Fuzzy string matching}

#Delete empty rows according to station names. At some rows, ther is only reason of the cut without any additional information. Since we can not do much with them and number of them is not significant (292 observation, less than 1%), we omitted them.

cuts <- cuts[-which(cuts$UEVÇB == ""), ]
cuts <- cuts[!apply(cuts == "", 1, all),]

#Detect similiar names with Fuzzy Text matching.

uniqueNames <- unique(cuts$Santral.Ýsmi)
name_distances <- list()
i <- 1
for (ind in uniqueNames){
  name_distances[[i]] <- agrep(ind, uniqueNames, value=T)
  i <- i+1
}
name_distances <- unique(Filter(function(x) {length(x) > 1}, name_distances))
#Fixing detected string issues.
cuts <- data.frame(lapply(cuts, function(x) {
   gsub("Ý", "i", x)
 }))
cuts <- data.frame(lapply(cuts, function(x) {
   gsub("enerj.sa", "enerjisa", x)
 }))
cuts <- data.frame(lapply(cuts, function(x) {
   gsub("yeniköy ts", "yeniköy tes", x)
 }))
cuts <- data.frame(lapply(cuts, function(x) {
   gsub("^ova elektrik", "gebze ova elektrik", x)
 }))
cuts <- data.frame(lapply(cuts, function(x) {
   gsub("yataðan .*", "yataðan tes", x)
 }))
cuts <- data.frame(lapply(cuts, function(x) {
   gsub("köklüce$", "köklüce hes", x)
 }))
cuts <- data.frame(lapply(cuts, function(x) {
   gsub(".* entek", "entek", x)
 }))
cuts <- data.frame(lapply(cuts, function(x) {
   gsub("kürtün-hes", "kürtün hes", x)
 }))
cuts <- data.frame(lapply(cuts, function(x) {
   gsub("^rwe_turcas_guney", "denizli rwe_turcas_guney", x)
 }))
cuts <- data.frame(lapply(cuts, function(x) {
   gsub("tekirdað santrali.*", "modern enerji tekirdað santrali", x)
 }))
cuts <- data.frame(lapply(cuts, function(x) {
   gsub("kangal .*", "kangal tes", x)
 }))
cuts <- data.frame(lapply(cuts, function(x) {
   gsub("karadað$", "karadað res", x)
 }))
cuts <- data.frame(lapply(cuts, function(x) {
   gsub("çatalaðzi ts", "çatalaðzý tes", x)
 }))
cuts <- data.frame(lapply(cuts, function(x) {
   gsub("termik santral[ýi]", "tes", x)
 }))
cuts <- data.frame(lapply(cuts, function(x) {
   gsub("hidro(elektrik santral[ýi]| e\\.?s)", "hes", x)
 }))
```


```{r Word count of cut reasons}

library(splitstackshape)
gerekcewordcount <- cSplit(cuts, "Gerekçe", sep = " ", direction = "long") %>%
      group_by(Gerekçe) %>%
      summarise(Count = n())

arrange(gerekcewordcount,desc(Count))
```