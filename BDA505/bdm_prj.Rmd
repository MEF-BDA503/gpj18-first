---
title: "BDA_HW"
author: "TBD"
date: "1 Ocak 2019"
output: html_document
---

# BDA505 Project for Group TBD

Group TBD Members:

Ýsmail Batur Usta

Efehan Danýþman

Özgür Özdemir

# Project Details and Aim

In this project, we used Airbnb dataset scraped via Inside Airbnb (http://insideairbnb.com/about.html) which is aiming to contribute the debate about how Airbnb is used in cities. Most of the data is scraped in November so the datas here are more or less updated. From total of 5 cities(Amsterdam, Athens, Barcelona, New York and Istanbul), our data are 970MB in total (unzipped) and divided into two main tables(one with listing and another one with availability). Gzipped files are available too. Below you can find the descriptions of variables.

Data has slightly over 100.000 observations at the listings table and several million observation at the calendar. Calendar tables are imported in gzipped format whereas listings table was imported as csv. We loaded the data with necessary methods. You can find out more about the AirBnb data in http://insideairbnb.com/get-the-data.html

## Data Structure

### LISTINGS

*id: Unique id of the house rented
*name: Name of the house
*host_id: Unique id of the host
*host_name: Name of the host
*neighbourhood_group: Neighbourhood group
*neighbourhood: Sub-category of the neighbourhood group
*latitude: Latitude of the house
*longitude: Longitude of the house
*room_type: Type of the room as a categorical variables
*price: Price in local currency
*minimum_nights: Minimum number of nights to stay
*number_of_reviews: Number of reviews
*last_review: Most recent reviews from the data scraped
*reviews_per_month:Average reviews per month
*calculated_host_listings_count: Number of listings of the host
*availability_365: Availability of the place out of 365 days

## AVAILABILITY

*listing_id: Unique id of the house rented
*date: date
*available: Binary variable true or false
*price: Price in US dollars

```{r, message=FALSE, warning=FALSE}
#Load necessary packages
library(RPostgreSQL)
library(tidyverse)
library(lubridate)
#Set localization
#Sys.setlocale(category = "LC_ALL", locale = "Turkish")
```


```{r, load_data, warning=FALSE}
#Import csv files to R environment, as well as gzipped calendar data for Istanbul and Barcelona
bar_list<- read.csv(url("https://github.com/MEF-BDA503/gpj18-first/blob/master/BDA505/barcelona_listings.csv?raw=true"), encoding= "UTF-8")
ist_list<- read.csv(url("https://github.com/MEF-BDA503/gpj18-first/blob/master/BDA505/istanbul_listings.csv?raw=true"), encoding= "Latin-1")
temp <- tempfile(fileext=".csv.gz")
download.file("https://github.com/MEF-BDA503/gpj18-first/blob/master/BDA505/calendar.csv.gz?raw=true", temp, mode='wb')
istc_gz<-gzfile(temp, 'ist_gz.csv')
ist_cal<-read.csv(istc_gz,header=T)
close(istc_gz)
# Barcelona dosyasını indirirken sıkıntı yaşıyorum, localden yükledim şimdilik
#temp2 <- tempfile(fileext=".csv.gz")
#download.file("https://github.com/MEF-BDA503/gpj18-first/blob/master/BDA505/calendar_barcelona.csv.gz?raw=true", temp2, mode='wb')
#barc_gz <- gzfile(temp2, 'barc_gz.csv')
bar_cal <- read.csv("C:\\Users\\MSİ\\Desktop\\calendar.csv", header=T)
#close(barc_gz)
```

```{r, include=FALSE}
pw <- {
  "bda505"
}
# loads the PostgreSQL driver
drv <- dbDriver("PostgreSQL")
# creates a connection to the postgres database
# note that "con" will be used later in each connection to the database
con <- dbConnect(drv, dbname = "postgres",
                 host = "localhost", port = 5432,
                 user = "postgres", password = pw)
rm(pw) # removes the password
```
# Data Transformation and Cleaning

The dataframes are mostly tidy, but they still need a few tweaks before going into analysis. Let's look at the structures first.

```{r, glimpse}
print("Istanbul Listings:")
str(ist_list)
print("Istanbul Calendar:")
str(ist_cal)
```

The formats of the variables match, however, id's should not be integers. Also splitting dates into three columns as year, month and day would be better.

```{r}
# Transform
ist_list$id <- as.factor(ist_list$id)
ist_list$host_id <- as.factor(ist_list$host_id)
ist_cal$listing_id <- as.factor(ist_cal$listing_id)
bar_list$id <- as.factor(bar_list$id)
bar_list$host_id <- as.factor(bar_list$host_id)
bar_cal$listing_id <- as.factor(bar_cal$listing_id)
#Tarihleri ayır
ist_cal$date <- ymd(ist_cal$date)
ist_cal <- ist_cal %>%
  mutate(year=year(date), month=month(date), day=day(date))
ist_cal$date <- NULL
ist_cal$price <- NULL
bar_cal <- bar_cal %>%
  mutate(year=year(date), month=month(date), day=day(date))
bar_cal$date <- NULL
bar_cal$price <- NULL
```

```{r}
#  
dbWriteTable(con, "istlist", 
             value = ist_list, append = TRUE, row.names = FALSE)
dbWriteTable(con, "istcal", 
             value = ist_cal, append = TRUE, row.names = FALSE)
dbWriteTable(con, "barlist", 
             value = bar_list, append = TRUE, row.names = FALSE)
dbWriteTable(con, "barcal", 
             value = bar_cal, append = TRUE, row.names = FALSE)


 
# query the data from postgreSQL 
df_postgres <- dbGetQuery(con, "SELECT ls.price, ls.host_name, cl.date FROM istlist ls
                                INNER JOIN istcal cl ON ls.id=cl.listing_id
                                WHERE ls.neighbourhood = 'Besiktas' AND cl.available='t'")
 

```

```{r}
dbDisconnect(con)
dbUnloadDriver(drv)
```

#Batur 9 Ocak
#Sehirleri tabloya eklemek için
listings <- listings %>% mutate(city = ifelse(longitude>28,"Istanbul",ifelse(longitude >4,"Amsterdam",ifelse(longitude>2, "Barcelona","New York"))))
#Bir plot
library(ggplot2)
numberofflats %>%
  filter(count > 2000) %>%
  ggplot(., aes(neighbourhood, count))+
  geom_col(aes(fill=city))+
  theme_bw()+
  theme(legend.position = "top", axis.text.x = element_text(angle=90, size = 12))+
  labs(title = "Number of BnB flats per Neighbourhood")+
  scale_fill_brewer(palette="Spectral")
